{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "xlrd - read excel  \n",
    "pandas - useful for data manipulation and its dataframes  \n",
    "os, sys - useful for file navigation  \n",
    "numpy - useful for matrices  \n",
    "math - constants and basic functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T01:39:04.217585Z",
     "start_time": "2021-02-09T01:38:55.383058Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics\n",
    "import plotly.express as px\n",
    "import kmeans1d\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from matplotlib import pyplot\n",
    "from math import sqrt\n",
    "from numpy import concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Files and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T01:39:04.369940Z",
     "start_time": "2021-02-09T01:39:04.219574Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def mult_quat(q1, q2):\n",
    "    w = q1[0]*q2[0] - np.dot(q1[1], q2[1])\n",
    "    v = np.add(np.cross(q1[1], q2[1]), q1[0]*q2[1])\n",
    "    v = np.add(v, q2[0]*q1[1])\n",
    "    return (w, v)\n",
    "               \n",
    "def conj_quat(quat):\n",
    "    return (quat[0], -1*quat[1])\n",
    "\n",
    "def inv_quat(quat):\n",
    "    conjugate = conj_quat(quat)\n",
    "    norm = math.sqrt(quat[0]**2 + quat[1][0]**2 + quat[1][1]**2 + quat[1][2]**2)\n",
    "    return (conjugate[0] / norm, conjugate[1] / norm)\n",
    "\n",
    "def rotate_quat(vect, rot_vect):\n",
    "    rot_vect_conj = inv_quat(rot_vect)\n",
    "    rotated_vect = mult_quat(rot_vect, vect)\n",
    "    rotated_vect = mult_quat(rotated_vect, rot_vect_conj)\n",
    "    return rotated_vect\n",
    "\n",
    "def knee_angle_deg(thigh_quat, shank_quat):\n",
    "    conjugate_thigh = conj_quat(thigh_quat)\n",
    "    relative_quat = mult_quat(conjugate_thigh, shank_quat)\n",
    "    knee_angle_w = math.acos(relative_quat[0])*360/math.pi\n",
    "    return knee_angle_w  # is it possible to extract sin component from unit vector and then average angle from that?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T01:39:04.414821Z",
     "start_time": "2021-02-09T01:39:04.374941Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def process_file(filepath):\n",
    "    print(filepath)\n",
    "    wb = xlrd.open_workbook(filepath)  # Open workbook\n",
    "    \n",
    "    subj_data = wb.sheet_by_index(1)  # Open Sheet2 which contains subject data\n",
    "    height = subj_data.cell_value(0, 1)\n",
    "    floor_to_shank_imu = subj_data.cell_value(1, 1)\n",
    "    floor_to_knee = subj_data.cell_value(2, 1)\n",
    "    floor_to_hip = subj_data.cell_value(3, 1)\n",
    "    knee_to_hip_imu = subj_data.cell_value(4, 1)\n",
    "    weight = subj_data.cell_value(5, 1)\n",
    "    gender = subj_data.cell_value(6, 1)\n",
    "    angle_offset1 = subj_data.cell_value(7, 1)\n",
    "    angle_offset2 = subj_data.cell_value(8, 1)\n",
    "    \n",
    "    imu_data = wb.sheet_by_index(0)  # Open Sheet1 which contains IMU Data\n",
    "    num_data_points = imu_data.nrows\n",
    "    compiled_data = {'Time': imu_data.col_values(1),\n",
    "                     'Time Between Readings': imu_data.col_values(2),\n",
    "                     'Angle': imu_data.col_values(5),\n",
    "                     'Thigh X Gravity Vector': [x * -1 for x in imu_data.col_values(7)], \n",
    "                     'Thigh Y Gravity Vector': [x * -1 for x in imu_data.col_values(8)], \n",
    "                     'Thigh Z Gravity Vector': imu_data.col_values(9),\n",
    "                     'Thigh X Gyroscope Vector': [x * -1 for x in imu_data.col_values(11)],\n",
    "                     'Thigh Y Gyroscope Vector': [x * -1 for x in imu_data.col_values(12)],\n",
    "                     'Thigh Z Gyroscope Vector': imu_data.col_values(13),\n",
    "                     'Thigh X Magnetometer Vector': [x * -1 for x in imu_data.col_values(15)],\n",
    "                     'Thigh Y Magnetometer Vector': [x * -1 for x in imu_data.col_values(16)],\n",
    "                     'Thigh Z Magnetometer Vector': imu_data.col_values(17),\n",
    "                     'Thigh X Euler Vector': [x * -1 for x in imu_data.col_values(19)],\n",
    "                     'Thigh Y Euler Vector': [x * -1 for x in imu_data.col_values(20)],\n",
    "                     'Thigh Z Euler Vector': imu_data.col_values(21),\n",
    "                     'Thigh X Acceleration Vector': [x * -1 for x in imu_data.col_values(23)],\n",
    "                     'Thigh Y Acceleration Vector': [x * -1 for x in imu_data.col_values(24)],\n",
    "                     'Thigh Z Acceleration Vector': imu_data.col_values(25),\n",
    "                     'Thigh X Linear Acceleration Vector': [x * -1 for x in imu_data.col_values(27)],\n",
    "                     'Thigh Y Linear Acceleration Vector': [x * -1 for x in imu_data.col_values(28)],\n",
    "                     'Thigh Z Linear Acceleration Vector': imu_data.col_values(29),\n",
    "                     'Thigh W Quaternion': imu_data.col_values(31),\n",
    "                     'Thigh X Quaternion': imu_data.col_values(32),\n",
    "                     'Thigh Y Quaternion': imu_data.col_values(33),\n",
    "                     'Thigh Z Quaternion': imu_data.col_values(34),\n",
    "                     'Weight': [weight] * num_data_points,\n",
    "                     'Height': [height] * num_data_points,\n",
    "                     'Floor to Shank IMU': [floor_to_shank_imu] * num_data_points,\n",
    "                     'Floor to Knee': [floor_to_knee] * num_data_points,\n",
    "                     'Floor to Hip': [floor_to_hip] * num_data_points,\n",
    "                     'Knee to Hip IMU': [knee_to_hip_imu] * num_data_points,\n",
    "                     'Gender': [gender] * num_data_points,\n",
    "                     'Angle_Offset_1': [angle_offset1] * num_data_points,\n",
    "                     'Angle_Offset_2': [angle_offset2] * num_data_points,\n",
    "                    }\n",
    "    thigh_x_ang_acc = []\n",
    "    thigh_y_ang_acc = []\n",
    "    thigh_z_ang_acc = []\n",
    "    thigh_grav_acc_cum = []\n",
    "#     thigh_roll = []\n",
    "#     thigh_pitch = []\n",
    "#     thigh_yaw = []\n",
    "    for i in range(1, num_data_points):\n",
    "        thigh_x_ang_acc.append((compiled_data['Thigh X Gyroscope Vector'][i] - compiled_data['Thigh X Gyroscope Vector'][i-1])/compiled_data['Time Between Readings'][i])\n",
    "        thigh_y_ang_acc.append((compiled_data['Thigh Y Gyroscope Vector'][i] - compiled_data['Thigh Y Gyroscope Vector'][i-1])/compiled_data['Time Between Readings'][i])\n",
    "        thigh_z_ang_acc.append((compiled_data['Thigh Z Gyroscope Vector'][i] - compiled_data['Thigh Z Gyroscope Vector'][i-1])/compiled_data['Time Between Readings'][i])\n",
    "        thigh_grav_acc_cum.append(sqrt(abs(compiled_data['Thigh X Gravity Vector'][i]**2) + abs(compiled_data['Thigh Y Gravity Vector'][i]**2) + abs(compiled_data['Thigh Z Gravity Vector'][i]**2)))\n",
    "#         thigh_roll_temp = 180 / math.pi * math.atan(compiled_data['Thigh X Gravity Vector'][i] / sqrt(abs(compiled_data['Thigh Z Gravity Vector'][i]**2) + abs(compiled_data['Thigh Y Gravity Vector'][i]**2)))\n",
    "#         thigh_roll.append(thigh_roll_temp)\n",
    "#         thigh_pitch_temp = 180 / math.pi * math.atan(compiled_data['Thigh Z Gravity Vector'][i] / sqrt(abs(compiled_data['Thigh X Gravity Vector'][i]**2) + abs(compiled_data['Thigh Y Gravity Vector'][i]**2)))\n",
    "#         thigh_pitch.append(thigh_pitch_temp)\n",
    "#         thigh_yaw_temp = 180 / math.pi * math.atan(compiled_data['Thigh Y Gravity Vector'][i] / sqrt(abs(compiled_data['Thigh X Gravity Vector'][i]**2) + abs(compiled_data['Thigh Z Gravity Vector'][i]**2)))\n",
    "#         thigh_yaw.append(thigh_yaw_temp) \n",
    "\n",
    "    for k in compiled_data:\n",
    "        compiled_data.update({k: compiled_data.get(k)[1:]})\n",
    "    compiled_data.update({'Thigh X Angular Acceleration': thigh_x_ang_acc})\n",
    "    compiled_data.update({'Thigh Y Angular Acceleration': thigh_y_ang_acc})\n",
    "    compiled_data.update({'Thigh Z Angular Acceleration': thigh_z_ang_acc})\n",
    "    compiled_data.update({'Thigh Gravity Vector Cumulated': thigh_grav_acc_cum})\n",
    "#     compiled_data.update({'Thigh Roll': thigh_roll})\n",
    "#     compiled_data.update({'Thigh Pitch': thigh_pitch})\n",
    "#     compiled_data.update({'Thigh Yaw': thigh_yaw})\n",
    "\n",
    "    df = pd.DataFrame(compiled_data)\n",
    "    return df, num_data_points-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T01:39:42.839017Z",
     "start_time": "2021-02-09T01:39:04.416816Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Harm_Jordan_Walking.xlsx\n",
      "Harm_Jordan_Walking.xlsx - 3344\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Harm_Jordan_Walking2.xlsx\n",
      "Harm_Jordan_Walking2.xlsx - 3361\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Harm_Jordan_Walking3.xlsx\n",
      "Harm_Jordan_Walking3.xlsx - 3326\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Harm_Jordan_Walking4.xlsx\n",
      "Harm_Jordan_Walking4.xlsx - 3332\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Harm_Jordan_Walking5.xlsx\n",
      "Harm_Jordan_Walking5.xlsx - 3354\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Keller_Emily_Walking.xlsx\n",
      "Keller_Emily_Walking.xlsx - 3348\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Keller_Emily_Walking2.xlsx\n",
      "Keller_Emily_Walking2.xlsx - 3335\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Keller_Emily_Walking3.xlsx\n",
      "Keller_Emily_Walking3.xlsx - 3340\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Keller_Emily_Walking4.xlsx\n",
      "Keller_Emily_Walking4.xlsx - 3342\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Keller_Emily_Walking5.xlsx\n",
      "Keller_Emily_Walking5.xlsx - 3346\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Kyu_Alex_Walking.xlsx\n",
      "Kyu_Alex_Walking.xlsx - 3370\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Kyu_Alex_Walking2.xlsx\n",
      "Kyu_Alex_Walking2.xlsx - 3375\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Kyu_Alex_Walking3.xlsx\n",
      "Kyu_Alex_Walking3.xlsx - 3349\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Kyu_Alex_Walking4.xlsx\n",
      "Kyu_Alex_Walking4.xlsx - 3361\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Kyu_Alex_Walking5.xlsx\n",
      "Kyu_Alex_Walking5.xlsx - 3373\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Kyu_Anthony_Walking.xlsx\n",
      "Kyu_Anthony_Walking.xlsx - 3354\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Kyu_Anthony_Walking2.xlsx\n",
      "Kyu_Anthony_Walking2.xlsx - 3344\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Kyu_Anthony_Walking3.xlsx\n",
      "Kyu_Anthony_Walking3.xlsx - 3371\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Kyu_Anthony_Walking4.xlsx\n",
      "Kyu_Anthony_Walking4.xlsx - 3362\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\Kyu_Anthony_Walking5.xlsx\n",
      "Kyu_Anthony_Walking5.xlsx - 3330\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\McKnight_Michael_Walking.xlsx\n",
      "McKnight_Michael_Walking.xlsx - 3335\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\McKnight_Michael_Walking2.xlsx\n",
      "McKnight_Michael_Walking2.xlsx - 3328\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\McKnight_Michael_Walking3.xlsx\n",
      "McKnight_Michael_Walking3.xlsx - 3327\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\McKnight_Michael_Walking4.xlsx\n",
      "McKnight_Michael_Walking4.xlsx - 3325\n",
      "C:\\Users\\Alexander\\Documents\\Documents\\Cybathlon\\cybathlon\\ML Code\\ml_data_v2\\McKnight_Michael_Walking5.xlsx\n",
      "McKnight_Michael_Walking5.xlsx - 3340\n",
      "Total Data Points: 83672\n"
     ]
    }
   ],
   "source": [
    "init_num_data_points = 0\n",
    "df_total = None\n",
    "df_list = []\n",
    "for i in os.listdir(os.getcwd() + \"/ml_data_v2\"):\n",
    "    if i[0] is not '~':\n",
    "        df, num_data_points = process_file(os.getcwd() + \"\\\\ml_data_v2\\\\\" + i)\n",
    "        print(str(i) + \" - \" + str(num_data_points))\n",
    "        init_num_data_points += num_data_points\n",
    "        df_list.append(df)\n",
    "        if df_total is None:\n",
    "            df_total = df\n",
    "        else:\n",
    "            df_total = pd.concat([df_total, df], axis=0).reset_index(drop=True)\n",
    "# print(df_total)\n",
    "print(\"Total Data Points: \" + str(init_num_data_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T02:12:54.634638Z",
     "start_time": "2021-01-26T02:12:54.534905Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig1 = px.line(list(df_total['Pitch Difference']))\n",
    "# fig1.show()\n",
    "# fig2 = px.line(list(df_total['Thigh Pitch']))\n",
    "# fig2.show()\n",
    "df_temp = pd.DataFrame(df_total.values[2000:2500, :])\n",
    "df_temp.columns = df_total.columns\n",
    "# fig2 = px.line(df_temp, x='Time', y='Thigh Pitch')\n",
    "# fig2.show()\n",
    "# fig3 = px.line(df_temp, x='Time', y='Shank Pitch')\n",
    "# fig3.show()\n",
    "fig1 = px.line(df_temp, x='Time', y=['Angle'])\n",
    "fig1.show()\n",
    "# fig4 = px.line(df_temp, x='Time', y='PredictedKneeAngle')\n",
    "# fig4.show()\n",
    "# print(list(df_total['Pitch Difference']))\n",
    "# fig3 = px.histogram(list(df_total['Shank Roll']))\n",
    "# fig3.show()\n",
    "# fig4 = px.histogram(list(df_total['Shank Pitch']))\n",
    "# fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5 = px.histogram(list(df_total['Thigh Roll']))\n",
    "fig5.show()\n",
    "fig6 = px.histogram(list(df_total['Thigh Pitch']))\n",
    "fig6.show()\n",
    "fig7 = px.histogram(list(df_total['Shank Roll']))\n",
    "fig7.show()\n",
    "fig8 = px.histogram(list(df_total['Shank Pitch']))\n",
    "fig8.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Estimated Knee Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T04:52:14.481340Z",
     "start_time": "2020-12-28T04:52:14.468375Z"
    }
   },
   "outputs": [],
   "source": [
    "# angles = []\n",
    "# angles2 = []\n",
    "# # print(len(df_total))\n",
    "# for i in range(init_num_data_points):\n",
    "#     shank_quat = (df_total['Shank W Quaternion'][i].astype('float64'), np.array([df_total['Shank X Quaternion'][i].astype('float64'), df_total['Shank Y Quaternion'][i].astype('float64'), df_total['Shank Z Quaternion'][i].astype('float64')]))\n",
    "# #     print(shank_quat)\n",
    "#     thigh_quat = (df_total['Thigh W Quaternion'][i].astype('float64'), np.array([df_total['Thigh X Quaternion'][i].astype('float64'), df_total['Thigh Y Quaternion'][i].astype('float64'), df_total['Thigh Z Quaternion'][i].astype('float64')]))\n",
    "# #     print(thigh_quat)\n",
    "# #     print(math.acos(abs(shank_quat[0]*thigh_quat[0] + shank_quat[1][0]*thigh_quat[1][0] + shank_quat[1][1]*thigh_quat[1][1] + shank_quat[1][2]*thigh_quat[1][2])))\n",
    "#     angles2.append(90-360/math.pi*math.acos(abs(shank_quat[0]*thigh_quat[0] + shank_quat[1][0]*thigh_quat[1][0] + shank_quat[1][1]*thigh_quat[1][1] + shank_quat[1][2]*thigh_quat[1][2])))\n",
    "\n",
    "#     rel_quat = mult_quat(inv_quat(thigh_quat), shank_quat)\n",
    "# #     print(rel_quat)\n",
    "#     angle = 90-360/math.pi*math.acos(rel_quat[0])\n",
    "#     print(str(i) + \" - \" + str(angle) + \" - \" + str(angles2[i]))\n",
    "#     angles.append(angle)\n",
    "# # print(angles)\n",
    "# df_total['PredictedKneeAngle'] = angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_total.PredictedKneeAngle\n",
    "# print(y)\n",
    "features = ['Thigh X Gravity Vector', 'Thigh Y Gravity Vector', 'Thigh Z Gravity Vector', \n",
    "            'Thigh X Gyroscope Vector', 'Thigh Y Gyroscope Vector', 'Thigh Z Gyroscope Vector',\n",
    "           'Thigh X Linear Acceleration Vector', 'Thigh Y Linear Acceleration Vector', 'Thigh Z Linear Acceleration Vector',\n",
    "           'Thigh X Angular Acceleration', 'Thigh Y Angular Acceleration', 'Thigh Z Angular Acceleration', 'Weight', 'Height',\n",
    "           'Floor to Shank IMU', 'Floor to Knee', 'Floor to Hip', 'Knee to Hip IMU']\n",
    "X = df_total[features]\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1, test_size=0.25)\n",
    "\n",
    "rf_angle_model = RandomForestRegressor(random_state=1, n_estimators=100)\n",
    "rf_angle_model.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "predicted_list = list(rf_angle_model.predict(val_X))\n",
    "# Calculate the mean absolute error of your Random Forest model on the validation data\n",
    "rf_val_mae = mean_absolute_error(predicted_list, val_y)\n",
    "\n",
    "mae_val = mean_absolute_error(predicted_list, val_y)\n",
    "error = []\n",
    "for i in range(len(list(predicted_list))):\n",
    "    error.append(abs(predicted_list[i] - list(val_y)[i]))\n",
    "# print(error)\n",
    "print(min(error))\n",
    "print(max(error))\n",
    "print(statistics.stdev(error))\n",
    "# print(statistics.mean(error))\n",
    "# print(error)\n",
    "\n",
    "df_test = px.data.tips()\n",
    "fig = px.histogram(error)\n",
    "fig.show()\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "## Attempt #1: <span class=\"girk\">K-means</span> Iteratively  \n",
    "Uses <span class=\"girk\">K-means</span> clustering iteratively to continuously divide clusters whose mae is above the median mae of all clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_optimizer_helper(current_clusters,\n",
    "                             current_centroids,\n",
    "                             df,\n",
    "                             n,\n",
    "                             clf=None,\n",
    "                             cent_dict=None):\n",
    "    if n > 0:\n",
    "        cent_dict = {}\n",
    "        for i in range(len(current_centroids)):\n",
    "            cent_dict.update({i: current_centroids[i]})\n",
    "        df['angle_cluster'] = current_clusters\n",
    "        clf = RandomForestClassifier(n_jobs=2,\n",
    "                                     random_state=0,\n",
    "                                     n_estimators=100)\n",
    "        y = df.angle_cluster\n",
    "        features = [\n",
    "            'Thigh X Gravity Vector', 'Thigh Y Gravity Vector',\n",
    "            'Thigh Z Gravity Vector', 'Thigh X Gyroscope Vector',\n",
    "            'Thigh Y Gyroscope Vector', 'Thigh Z Gyroscope Vector',\n",
    "            'Thigh X Linear Acceleration Vector',\n",
    "            'Thigh Y Linear Acceleration Vector',\n",
    "            'Thigh Z Linear Acceleration Vector',\n",
    "            'Thigh X Angular Acceleration', 'Thigh Y Angular Acceleration',\n",
    "            'Thigh Z Angular Acceleration', 'Weight', 'Height',\n",
    "            'Floor to Shank IMU', 'Floor to Knee', 'Floor to Hip',\n",
    "            'Knee to Hip IMU'\n",
    "        ]\n",
    "        features_full = [\n",
    "            'Thigh X Gravity Vector', 'Thigh Y Gravity Vector',\n",
    "            'Thigh Z Gravity Vector', 'Thigh X Gyroscope Vector',\n",
    "            'Thigh Y Gyroscope Vector', 'Thigh Z Gyroscope Vector',\n",
    "            'Thigh X Linear Acceleration Vector',\n",
    "            'Thigh Y Linear Acceleration Vector',\n",
    "            'Thigh Z Linear Acceleration Vector',\n",
    "            'Thigh X Angular Acceleration', 'Thigh Y Angular Acceleration',\n",
    "            'Thigh Z Angular Acceleration', 'Weight', 'Height',\n",
    "            'Floor to Shank IMU', 'Floor to Knee', 'Floor to Hip',\n",
    "            'Knee to Hip IMU', 'PredictedKneeAngle'\n",
    "        ]\n",
    "        X = df[features_full]\n",
    "        # Split into validation and training data\n",
    "        train_X, val_X, train_y, val_y = train_test_split(X,\n",
    "                                                          y,\n",
    "                                                          random_state=1,\n",
    "                                                          test_size=0.25)\n",
    "        train_X = train_X[features]\n",
    "        clf.fit(train_X, train_y)\n",
    "        mae = []\n",
    "        for i in range(len(current_centroids)):\n",
    "            #         print(val_X[val_y==i][features])\n",
    "            #         print(val_X[val_y==i]['PredictedKneeAngle'])\n",
    "            predicted_list = []\n",
    "            if len(val_X[val_y == i][features]) == 0:\n",
    "                mae.append(None)\n",
    "                continue\n",
    "            prediction_keys = clf.predict(val_X[val_y == i][features])\n",
    "            for j in prediction_keys:\n",
    "                predicted_list.append(cent_dict[j])\n",
    "#             print(predicted_list)\n",
    "            mae.append(\n",
    "                mean_absolute_error(predicted_list,\n",
    "                                    val_X[val_y == i]['PredictedKneeAngle']))\n",
    "        print(mae)\n",
    "        mae_clean = []\n",
    "        for i in mae:\n",
    "            if i is not None:\n",
    "                mae_clean.append(i)\n",
    "        med_mae = statistics.median(mae_clean)\n",
    "        print(med_mae)\n",
    "        split_clusters = []\n",
    "        for i in range(len(current_centroids)):\n",
    "            if mae[i] is None:\n",
    "                split_clusters.append(None)\n",
    "                continue\n",
    "            if med_mae < mae[i]:\n",
    "                split_clusters.append(i)\n",
    "        print(split_clusters)\n",
    "        split_clusters.reverse()\n",
    "        for i in split_clusters:\n",
    "            if i is None:\n",
    "                continue\n",
    "            angles_to_split = list(\n",
    "                df[df['angle_cluster'] == i]['PredictedKneeAngle'])\n",
    "            new_cluster, new_centroids = kmeans1d.cluster(angles_to_split, 2)\n",
    "\n",
    "            for j in range(len(df['angle_cluster'])):\n",
    "                #                 print(str(df['angle_cluster'][j]) + \" - \" + str(i) + \" - \" + str(df['angle_cluster'][j] == i))\n",
    "                if df['angle_cluster'][j] == i:\n",
    "                    df['angle_cluster'][j] = new_cluster.pop(0) + i\n",
    "                elif df['angle_cluster'][j] > i:\n",
    "                    df['angle_cluster'][j] = df['angle_cluster'][j] + 1\n",
    "#             print(2 in list(df['angle_cluster']))\n",
    "#             print(new_cluster)\n",
    "            current_centroids.pop(i)\n",
    "            current_centroids += new_centroids\n",
    "        current_centroids = sorted(current_centroids)\n",
    "        return cluster_optimizer_helper(list(df['angle_cluster']),\n",
    "                                        current_centroids, df, n - 1, clf,\n",
    "                                        cent_dict)\n",
    "    else:\n",
    "        cent_dict = {}\n",
    "        for i in range(len(current_centroids)):\n",
    "            cent_dict.update({i: current_centroids[i]})\n",
    "        return clf, current_centroids, list(df['angle_cluster']), cent_dict\n",
    "\n",
    "\n",
    "#         print(df['angle_cluster'])\n",
    "#     print(mae)\n",
    "#     print(med_mae)\n",
    "\n",
    "clusters, centroids = kmeans1d.cluster(angles, 2)\n",
    "# temp_df = df_total\n",
    "model, centroids_final, clusters_final, centroid_dictionary = cluster_optimizer_helper(\n",
    "    clusters, centroids, df_total, 10)\n",
    "print(centroids_final)\n",
    "print(clusters_final)\n",
    "print(centroid_dictionary)\n",
    "print(model)\n",
    "\n",
    "# Calculate the mean absolute error of your Random Forest model on the validation data\n",
    "rf_val_mae = mean_absolute_error(model.predict(val_X), val_y)\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt #2: K-means Clusters Constant\n",
    "Clusters using K-means and does a Random Forest Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_once, centroids_once = kmeans1d.cluster(angles, 20)\n",
    "# print(clusters_once)\n",
    "# print(centroids_once)\n",
    "\n",
    "cent_dict = {}\n",
    "for i in range(len(centroids_once)):\n",
    "    cent_dict.update({i: centroids_once[i]})\n",
    "# print(cent_dict)\n",
    "\n",
    "\n",
    "# print(df_total)    \n",
    "df_total['angle_cluster'] = clusters_once\n",
    "clf = RandomForestClassifier(n_jobs=2, random_state=0, n_estimators=100)\n",
    "y = df_total.angle_cluster\n",
    "features = ['Thigh X Gravity Vector', 'Thigh Y Gravity Vector', 'Thigh Z Gravity Vector', \n",
    "            'Thigh X Gyroscope Vector', 'Thigh Y Gyroscope Vector', 'Thigh Z Gyroscope Vector',\n",
    "            'Thigh X Linear Acceleration Vector', 'Thigh Y Linear Acceleration Vector', 'Thigh Z Linear Acceleration Vector',\n",
    "            'Thigh X Angular Acceleration', 'Thigh Y Angular Acceleration', 'Thigh Z Angular Acceleration', 'Weight', 'Height',\n",
    "            'Floor to Shank IMU', 'Floor to Knee', 'Floor to Hip', 'Knee to Hip IMU']\n",
    "features_full = ['Thigh X Gravity Vector', 'Thigh Y Gravity Vector', 'Thigh Z Gravity Vector', \n",
    "            'Thigh X Gyroscope Vector', 'Thigh Y Gyroscope Vector', 'Thigh Z Gyroscope Vector',\n",
    "            'Thigh X Linear Acceleration Vector', 'Thigh Y Linear Acceleration Vector', 'Thigh Z Linear Acceleration Vector',\n",
    "            'Thigh X Angular Acceleration', 'Thigh Y Angular Acceleration', 'Thigh Z Angular Acceleration', 'Weight', 'Height',\n",
    "            'Floor to Shank IMU', 'Floor to Knee', 'Floor to Hip', 'Knee to Hip IMU', 'PredictedKneeAngle']\n",
    "X = df_total[features_full]\n",
    "\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1, test_size=0.25)\n",
    "train_X = train_X[features]\n",
    "val_y_converted = val_X['PredictedKneeAngle']\n",
    "val_X = val_X[features]\n",
    "clf.fit(train_X, train_y)\n",
    "predicted_list = []\n",
    "# print(val_X)\n",
    "# print(clf.predict(val_X))\n",
    "# print(val_X.iloc[[0]])\n",
    "# print(clf.predict(val_X.iloc[[0]]))\n",
    "keys_list = clf.predict(val_X)\n",
    "for i in keys_list:\n",
    "#     print(i)\n",
    "#     print(clf.predict(i))\n",
    "    predicted_list.append(cent_dict[i])\n",
    "\n",
    "# print(predicted_list)\n",
    "\n",
    "mae_val = mean_absolute_error(predicted_list, val_y_converted)\n",
    "error = []\n",
    "for i in range(len(predicted_list)):\n",
    "    error.append(abs(predicted_list[i] - list(val_y_converted)[i]))\n",
    "# print(error)\n",
    "print(min(error))\n",
    "print(max(error))\n",
    "print(statistics.stdev(error))\n",
    "# print(statistics.mean(error))\n",
    "# print(error)\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {}\".format(mae_val))\n",
    "\n",
    "df_test = px.data.tips()\n",
    "fig = px.histogram(error)\n",
    "fig.show()\n",
    "# print(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "## LSTM RNN Model\n",
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T01:42:18.865652Z",
     "start_time": "2021-02-09T01:42:18.829717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Time Between Readings</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Thigh X Gravity Vector</th>\n",
       "      <th>Thigh Y Gravity Vector</th>\n",
       "      <th>Thigh Z Gravity Vector</th>\n",
       "      <th>Thigh X Gyroscope Vector</th>\n",
       "      <th>Thigh Y Gyroscope Vector</th>\n",
       "      <th>Thigh Z Gyroscope Vector</th>\n",
       "      <th>Thigh X Magnetometer Vector</th>\n",
       "      <th>...</th>\n",
       "      <th>Floor to Knee</th>\n",
       "      <th>Floor to Hip</th>\n",
       "      <th>Knee to Hip IMU</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Angle_Offset_1</th>\n",
       "      <th>Angle_Offset_2</th>\n",
       "      <th>Thigh X Angular Acceleration</th>\n",
       "      <th>Thigh Y Angular Acceleration</th>\n",
       "      <th>Thigh Z Angular Acceleration</th>\n",
       "      <th>Thigh Gravity Vector Cumulated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>37756.0</td>\n",
       "      <td>17848.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>9.73</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-15.50</td>\n",
       "      <td>14.38</td>\n",
       "      <td>104.75</td>\n",
       "      <td>-30.50</td>\n",
       "      <td>...</td>\n",
       "      <td>475.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>9.802168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>54712.0</td>\n",
       "      <td>16952.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-11.50</td>\n",
       "      <td>13.19</td>\n",
       "      <td>103.81</td>\n",
       "      <td>-32.25</td>\n",
       "      <td>...</td>\n",
       "      <td>475.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>9.800597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>63788.0</td>\n",
       "      <td>9072.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-11.50</td>\n",
       "      <td>13.19</td>\n",
       "      <td>103.81</td>\n",
       "      <td>-32.25</td>\n",
       "      <td>...</td>\n",
       "      <td>475.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.800597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>83632.0</td>\n",
       "      <td>19840.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>9.61</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>13.38</td>\n",
       "      <td>6.88</td>\n",
       "      <td>100.75</td>\n",
       "      <td>-32.25</td>\n",
       "      <td>...</td>\n",
       "      <td>475.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>9.800010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100404.0</td>\n",
       "      <td>16764.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.54</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>36.63</td>\n",
       "      <td>1.37</td>\n",
       "      <td>98.94</td>\n",
       "      <td>-33.00</td>\n",
       "      <td>...</td>\n",
       "      <td>475.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>-0.000329</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>9.797495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  Time Between Readings  Angle  Thigh X Gravity Vector  \\\n",
       "0   37756.0                17848.0   54.0                    9.73   \n",
       "1   54712.0                16952.0   52.0                    9.69   \n",
       "2   63788.0                 9072.0   52.0                    9.69   \n",
       "3   83632.0                19840.0   48.0                    9.61   \n",
       "4  100404.0                16764.0   45.0                    9.54   \n",
       "\n",
       "   Thigh Y Gravity Vector  Thigh Z Gravity Vector  Thigh X Gyroscope Vector  \\\n",
       "0                   -1.00                   -0.64                    -15.50   \n",
       "1                   -1.34                   -0.60                    -11.50   \n",
       "2                   -1.34                   -0.60                    -11.50   \n",
       "3                   -1.84                   -0.55                     13.38   \n",
       "4                   -2.17                   -0.52                     36.63   \n",
       "\n",
       "   Thigh Y Gyroscope Vector  Thigh Z Gyroscope Vector  \\\n",
       "0                     14.38                    104.75   \n",
       "1                     13.19                    103.81   \n",
       "2                     13.19                    103.81   \n",
       "3                      6.88                    100.75   \n",
       "4                      1.37                     98.94   \n",
       "\n",
       "   Thigh X Magnetometer Vector  ...  Floor to Knee  Floor to Hip  \\\n",
       "0                       -30.50  ...          475.0         852.0   \n",
       "1                       -32.25  ...          475.0         852.0   \n",
       "2                       -32.25  ...          475.0         852.0   \n",
       "3                       -32.25  ...          475.0         852.0   \n",
       "4                       -33.00  ...          475.0         852.0   \n",
       "\n",
       "   Knee to Hip IMU  Gender  Angle_Offset_1  Angle_Offset_2  \\\n",
       "0             10.0    Male             8.2             5.2   \n",
       "1             10.0    Male             8.2             5.2   \n",
       "2             10.0    Male             8.2             5.2   \n",
       "3             10.0    Male             8.2             5.2   \n",
       "4             10.0    Male             8.2             5.2   \n",
       "\n",
       "   Thigh X Angular Acceleration  Thigh Y Angular Acceleration  \\\n",
       "0                      0.000599                     -0.000143   \n",
       "1                      0.000236                     -0.000070   \n",
       "2                      0.000000                      0.000000   \n",
       "3                      0.001254                     -0.000318   \n",
       "4                      0.001387                     -0.000329   \n",
       "\n",
       "   Thigh Z Angular Acceleration  Thigh Gravity Vector Cumulated  \n",
       "0                      0.000445                        9.802168  \n",
       "1                     -0.000055                        9.800597  \n",
       "2                      0.000000                        9.800597  \n",
       "3                     -0.000154                        9.800010  \n",
       "4                     -0.000108                        9.797495  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T03:10:27.036644Z",
     "start_time": "2021-02-09T03:10:26.066241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (83672, 38)\n",
      "3340\n",
      "3357\n",
      "3322\n",
      "3328\n",
      "3350\n",
      "3344\n",
      "3331\n",
      "3336\n",
      "3338\n",
      "3342\n",
      "3366\n",
      "3371\n",
      "3345\n",
      "3357\n",
      "3369\n",
      "3350\n",
      "3340\n",
      "3367\n",
      "3358\n",
      "3326\n",
      "3331\n",
      "3324\n",
      "3323\n",
      "3321\n",
      "3336\n",
      "Shape after processing: (83572, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Thigh X Gravity Vector</th>\n",
       "      <th>Thigh Y Gravity Vector</th>\n",
       "      <th>Thigh Z Gravity Vector</th>\n",
       "      <th>Thigh X Gyroscope Vector</th>\n",
       "      <th>Thigh Y Gyroscope Vector</th>\n",
       "      <th>Thigh Z Gyroscope Vector</th>\n",
       "      <th>Thigh X Linear Acceleration Vector</th>\n",
       "      <th>Thigh Y Linear Acceleration Vector</th>\n",
       "      <th>...</th>\n",
       "      <th>Thigh Z Gyroscope Vector(t-1)</th>\n",
       "      <th>Thigh X Linear Acceleration Vector(t-1)</th>\n",
       "      <th>Thigh Y Linear Acceleration Vector(t-1)</th>\n",
       "      <th>Thigh Z Linear Acceleration Vector(t-1)</th>\n",
       "      <th>Thigh X Angular Acceleration(t-1)</th>\n",
       "      <th>Thigh Y Angular Acceleration(t-1)</th>\n",
       "      <th>Thigh Z Angular Acceleration(t-1)</th>\n",
       "      <th>Angle(t-1)</th>\n",
       "      <th>Angle(t)</th>\n",
       "      <th>Angle(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.61</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>13.38</td>\n",
       "      <td>6.88</td>\n",
       "      <td>100.75</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>103.81</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.54</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>36.63</td>\n",
       "      <td>1.37</td>\n",
       "      <td>98.94</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.86</td>\n",
       "      <td>...</td>\n",
       "      <td>100.75</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>48.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.51</td>\n",
       "      <td>-2.32</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>57.25</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.12</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>1.51</td>\n",
       "      <td>...</td>\n",
       "      <td>98.94</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>-0.000329</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>45.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.43</td>\n",
       "      <td>-2.62</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>63.75</td>\n",
       "      <td>10.00</td>\n",
       "      <td>80.50</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>1.31</td>\n",
       "      <td>...</td>\n",
       "      <td>91.12</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>1.51</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000395</td>\n",
       "      <td>41.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.36</td>\n",
       "      <td>-2.88</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>60.88</td>\n",
       "      <td>17.50</td>\n",
       "      <td>79.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>80.50</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>-0.000605</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Female  Male  Thigh X Gravity Vector  Thigh Y Gravity Vector  \\\n",
       "3     0.0   1.0                    9.61                   -1.84   \n",
       "4     0.0   1.0                    9.54                   -2.17   \n",
       "5     0.0   1.0                    9.51                   -2.32   \n",
       "6     0.0   1.0                    9.43                   -2.62   \n",
       "7     0.0   1.0                    9.36                   -2.88   \n",
       "\n",
       "   Thigh Z Gravity Vector  Thigh X Gyroscope Vector  Thigh Y Gyroscope Vector  \\\n",
       "3                   -0.55                     13.38                      6.88   \n",
       "4                   -0.52                     36.63                      1.37   \n",
       "5                   -0.50                     57.25                      1.37   \n",
       "6                   -0.44                     63.75                     10.00   \n",
       "7                   -0.34                     60.88                     17.50   \n",
       "\n",
       "   Thigh Z Gyroscope Vector  Thigh X Linear Acceleration Vector  \\\n",
       "3                    100.75                               -0.90   \n",
       "4                     98.94                               -0.72   \n",
       "5                     91.12                               -0.44   \n",
       "6                     80.50                               -0.24   \n",
       "7                     79.12                                0.45   \n",
       "\n",
       "   Thigh Y Linear Acceleration Vector  ...  Thigh Z Gyroscope Vector(t-1)  \\\n",
       "3                                0.44  ...                         103.81   \n",
       "4                                0.86  ...                         100.75   \n",
       "5                                1.51  ...                          98.94   \n",
       "6                                1.31  ...                          91.12   \n",
       "7                                1.23  ...                          80.50   \n",
       "\n",
       "   Thigh X Linear Acceleration Vector(t-1)  \\\n",
       "3                                    -0.73   \n",
       "4                                    -0.90   \n",
       "5                                    -0.72   \n",
       "6                                    -0.44   \n",
       "7                                    -0.24   \n",
       "\n",
       "   Thigh Y Linear Acceleration Vector(t-1)  \\\n",
       "3                                     0.39   \n",
       "4                                     0.44   \n",
       "5                                     0.86   \n",
       "6                                     1.51   \n",
       "7                                     1.31   \n",
       "\n",
       "   Thigh Z Linear Acceleration Vector(t-1)  Thigh X Angular Acceleration(t-1)  \\\n",
       "3                                    -0.92                           0.000000   \n",
       "4                                    -0.67                           0.001254   \n",
       "5                                    -0.38                           0.001387   \n",
       "6                                    -0.08                           0.001041   \n",
       "7                                     0.36                           0.000370   \n",
       "\n",
       "   Thigh Y Angular Acceleration(t-1)  Thigh Z Angular Acceleration(t-1)  \\\n",
       "3                           0.000000                           0.000000   \n",
       "4                          -0.000318                          -0.000154   \n",
       "5                          -0.000329                          -0.000108   \n",
       "6                           0.000000                          -0.000395   \n",
       "7                           0.000491                          -0.000605   \n",
       "\n",
       "   Angle(t-1)  Angle(t)  Angle(t+1)  \n",
       "3        52.0      48.0        45.0  \n",
       "4        48.0      45.0        41.0  \n",
       "5        45.0      41.0        37.0  \n",
       "6        41.0      37.0        34.0  \n",
       "7        37.0      34.0        34.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape: \" + str(np.shape(df_total)))\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, const_cols=[], input_cols=[], output_cols=[], \n",
    "                         n_in=1, n_out=1, dropnan=True, include_current=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "#     df.drop(df[drop_cols], axis=1, inplace=True)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df[input_cols].shift(i))\n",
    "        names += [('%s(t-%d)' % (input_cols[j], i)) for j in range(len(input_cols))]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df[output_cols].shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('%s(t)' % (output_cols[j])) for j in range(len(output_cols))]\n",
    "        else:\n",
    "            names += [('%s(t+%d)' % (output_cols[j], i)) for j in range(len(output_cols))]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "#     print(df[const_cols])\n",
    "    count_remove = 0\n",
    "    if include_current:\n",
    "        for i in output_cols:\n",
    "            if i in input_cols:\n",
    "                input_cols.remove(i)\n",
    "                count_remove += 1\n",
    "        agg = pd.concat([df[input_cols], agg], axis=1)\n",
    "        num_inputs =  (n_in + 1)*(len(input_cols) + count_remove) + len(const_cols) - count_remove\n",
    "    else:\n",
    "        num_inputs =  n_in*len(input_cols) + len(const_cols)\n",
    "    agg = pd.concat([df[const_cols], agg], axis=1)\n",
    "#     print(agg)\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg, num_inputs, n_out\n",
    "\n",
    "sup_df_total_scaled = None\n",
    "sup_df_total_scaled_list = []\n",
    "sup_df_total_list = []\n",
    "scaler_list = []\n",
    "post_num_data_points = 0\n",
    "for df in df_list:\n",
    "    gender = list(df['Gender'])[0]\n",
    "\n",
    "    sup_df_total, num_inputs, num_outputs = series_to_supervised(\n",
    "        df, \n",
    "        const_cols=[\n",
    "#             'Weight', \n",
    "#             'Height', \n",
    "#             'Floor to Knee', \n",
    "#             'Floor to Hip', \n",
    "#             'Angle_Offset_1', 'Angle_Offset_2',\n",
    "        ],\n",
    "        input_cols=[\n",
    "            'Thigh X Gravity Vector', 'Thigh Y Gravity Vector', 'Thigh Z Gravity Vector', \n",
    "            'Thigh X Gyroscope Vector', 'Thigh Y Gyroscope Vector', 'Thigh Z Gyroscope Vector',\n",
    "            'Thigh X Linear Acceleration Vector', 'Thigh Y Linear Acceleration Vector', \n",
    "            'Thigh Z Linear Acceleration Vector', 'Thigh X Angular Acceleration', \n",
    "            'Thigh Y Angular Acceleration', 'Thigh Z Angular Acceleration', 'Angle'\n",
    "        ],\n",
    "        output_cols=[\n",
    "            'Angle'\n",
    "        ],\n",
    "        n_in=3, n_out=2, dropnan=True, include_current=True)\n",
    "\n",
    "    if gender == 'Male':\n",
    "        sup_df_total['Female'] = [0.0] * sup_df_total.shape[0]\n",
    "        sup_df_total['Male'] = [1.0] * sup_df_total.shape[0]\n",
    "    else:\n",
    "        sup_df_total['Female'] = [1.0] * sup_df_total.shape[0]\n",
    "        sup_df_total['Male'] = [0.0] * sup_df_total.shape[0]\n",
    "    sup_df_total.insert(0, 'Male', sup_df_total.pop('Male'))\n",
    "    sup_df_total.insert(0, 'Female', sup_df_total.pop('Female'))\n",
    "\n",
    "    if sup_df_total_scaled is None:\n",
    "        sup_df_total_scaled = sup_df_total\n",
    "    else:\n",
    "        sup_df_total_scaled = pd.concat([sup_df_total_scaled, sup_df_total], axis=0).reset_index(drop=True)\n",
    "    scaler_list.append(MinMaxScaler(feature_range=(0, 1)))\n",
    "    sup_df_total_list.append(sup_df_total)\n",
    "    sup_df_total_scaled_list.append(pd.DataFrame(scaler_list[len(scaler_list)-1].fit_transform(sup_df_total)))\n",
    "    print(sup_df_total.shape[0])\n",
    "    post_num_data_points += sup_df_total.shape[0]\n",
    "    \n",
    "num_inputs = num_inputs + 3  # add three - 2 for male and female one hot encoding, \n",
    "                             # 1 for current predicted knee angle\n",
    "num_outputs = num_outputs - 1  # subtract 1 - we are not outputting for current predicted knee angle, \n",
    "                               # only the future angles\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "col_names = sup_df_total_scaled.columns\n",
    "sup_df_total_scaled = pd.DataFrame(scaler.fit_transform(sup_df_total_scaled.values))\n",
    "sup_df_total_scaled.columns = col_names\n",
    "    \n",
    "print(\"Shape after processing: \" + str(np.shape(sup_df_total_scaled)))\n",
    "# sup_df_total_scaled.head()\n",
    "# sup_df_total_scaled_list[0].head()\n",
    "# pd.DataFrame(scaler.inverse_transform(sup_df_total_scaled.values)).head()\n",
    "sup_df_total_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T03:10:27.744848Z",
     "start_time": "2021-02-09T03:10:27.700966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Thigh X Gravity Vector</th>\n",
       "      <th>Thigh Y Gravity Vector</th>\n",
       "      <th>Thigh Z Gravity Vector</th>\n",
       "      <th>Thigh X Gyroscope Vector</th>\n",
       "      <th>Thigh Y Gyroscope Vector</th>\n",
       "      <th>Thigh Z Gyroscope Vector</th>\n",
       "      <th>Thigh X Linear Acceleration Vector</th>\n",
       "      <th>Thigh Y Linear Acceleration Vector</th>\n",
       "      <th>...</th>\n",
       "      <th>Thigh Y Gyroscope Vector(t-1)</th>\n",
       "      <th>Thigh Z Gyroscope Vector(t-1)</th>\n",
       "      <th>Thigh X Linear Acceleration Vector(t-1)</th>\n",
       "      <th>Thigh Y Linear Acceleration Vector(t-1)</th>\n",
       "      <th>Thigh Z Linear Acceleration Vector(t-1)</th>\n",
       "      <th>Thigh X Angular Acceleration(t-1)</th>\n",
       "      <th>Thigh Y Angular Acceleration(t-1)</th>\n",
       "      <th>Thigh Z Angular Acceleration(t-1)</th>\n",
       "      <th>Angle(t-1)</th>\n",
       "      <th>Angle(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960986</td>\n",
       "      <td>0.498842</td>\n",
       "      <td>0.505102</td>\n",
       "      <td>0.344763</td>\n",
       "      <td>0.655868</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>0.417934</td>\n",
       "      <td>0.491637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673974</td>\n",
       "      <td>0.672319</td>\n",
       "      <td>0.420905</td>\n",
       "      <td>0.491060</td>\n",
       "      <td>0.533898</td>\n",
       "      <td>0.425561</td>\n",
       "      <td>0.517579</td>\n",
       "      <td>0.545818</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.688312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.946612</td>\n",
       "      <td>0.473359</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.368504</td>\n",
       "      <td>0.640057</td>\n",
       "      <td>0.665675</td>\n",
       "      <td>0.421080</td>\n",
       "      <td>0.496482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655868</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>0.417934</td>\n",
       "      <td>0.491637</td>\n",
       "      <td>0.538406</td>\n",
       "      <td>0.458236</td>\n",
       "      <td>0.500586</td>\n",
       "      <td>0.540056</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940452</td>\n",
       "      <td>0.461776</td>\n",
       "      <td>0.511480</td>\n",
       "      <td>0.389560</td>\n",
       "      <td>0.640057</td>\n",
       "      <td>0.655007</td>\n",
       "      <td>0.425974</td>\n",
       "      <td>0.503980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640057</td>\n",
       "      <td>0.665675</td>\n",
       "      <td>0.421080</td>\n",
       "      <td>0.496482</td>\n",
       "      <td>0.543635</td>\n",
       "      <td>0.461698</td>\n",
       "      <td>0.500017</td>\n",
       "      <td>0.541785</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.597403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.924025</td>\n",
       "      <td>0.438610</td>\n",
       "      <td>0.519133</td>\n",
       "      <td>0.396197</td>\n",
       "      <td>0.664821</td>\n",
       "      <td>0.640518</td>\n",
       "      <td>0.429470</td>\n",
       "      <td>0.501673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640057</td>\n",
       "      <td>0.655007</td>\n",
       "      <td>0.425974</td>\n",
       "      <td>0.503980</td>\n",
       "      <td>0.549044</td>\n",
       "      <td>0.452696</td>\n",
       "      <td>0.517579</td>\n",
       "      <td>0.531064</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909651</td>\n",
       "      <td>0.418533</td>\n",
       "      <td>0.531888</td>\n",
       "      <td>0.393267</td>\n",
       "      <td>0.686341</td>\n",
       "      <td>0.638636</td>\n",
       "      <td>0.441531</td>\n",
       "      <td>0.500750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664821</td>\n",
       "      <td>0.640518</td>\n",
       "      <td>0.429470</td>\n",
       "      <td>0.501673</td>\n",
       "      <td>0.556978</td>\n",
       "      <td>0.435201</td>\n",
       "      <td>0.543826</td>\n",
       "      <td>0.523236</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.506494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Female  Male  Thigh X Gravity Vector  Thigh Y Gravity Vector  \\\n",
       "0     0.0   1.0                0.960986                0.498842   \n",
       "1     0.0   1.0                0.946612                0.473359   \n",
       "2     0.0   1.0                0.940452                0.461776   \n",
       "3     0.0   1.0                0.924025                0.438610   \n",
       "4     0.0   1.0                0.909651                0.418533   \n",
       "\n",
       "   Thigh Z Gravity Vector  Thigh X Gyroscope Vector  Thigh Y Gyroscope Vector  \\\n",
       "0                0.505102                  0.344763                  0.655868   \n",
       "1                0.508929                  0.368504                  0.640057   \n",
       "2                0.511480                  0.389560                  0.640057   \n",
       "3                0.519133                  0.396197                  0.664821   \n",
       "4                0.531888                  0.393267                  0.686341   \n",
       "\n",
       "   Thigh Z Gyroscope Vector  Thigh X Linear Acceleration Vector  \\\n",
       "0                  0.668145                            0.417934   \n",
       "1                  0.665675                            0.421080   \n",
       "2                  0.655007                            0.425974   \n",
       "3                  0.640518                            0.429470   \n",
       "4                  0.638636                            0.441531   \n",
       "\n",
       "   Thigh Y Linear Acceleration Vector  ...  Thigh Y Gyroscope Vector(t-1)  \\\n",
       "0                            0.491637  ...                       0.673974   \n",
       "1                            0.496482  ...                       0.655868   \n",
       "2                            0.503980  ...                       0.640057   \n",
       "3                            0.501673  ...                       0.640057   \n",
       "4                            0.500750  ...                       0.664821   \n",
       "\n",
       "   Thigh Z Gyroscope Vector(t-1)  Thigh X Linear Acceleration Vector(t-1)  \\\n",
       "0                       0.672319                                 0.420905   \n",
       "1                       0.668145                                 0.417934   \n",
       "2                       0.665675                                 0.421080   \n",
       "3                       0.655007                                 0.425974   \n",
       "4                       0.640518                                 0.429470   \n",
       "\n",
       "   Thigh Y Linear Acceleration Vector(t-1)  \\\n",
       "0                                 0.491060   \n",
       "1                                 0.491637   \n",
       "2                                 0.496482   \n",
       "3                                 0.503980   \n",
       "4                                 0.501673   \n",
       "\n",
       "   Thigh Z Linear Acceleration Vector(t-1)  Thigh X Angular Acceleration(t-1)  \\\n",
       "0                                 0.533898                           0.425561   \n",
       "1                                 0.538406                           0.458236   \n",
       "2                                 0.543635                           0.461698   \n",
       "3                                 0.549044                           0.452696   \n",
       "4                                 0.556978                           0.435201   \n",
       "\n",
       "   Thigh Y Angular Acceleration(t-1)  Thigh Z Angular Acceleration(t-1)  \\\n",
       "0                           0.517579                           0.545818   \n",
       "1                           0.500586                           0.540056   \n",
       "2                           0.500017                           0.541785   \n",
       "3                           0.517579                           0.531064   \n",
       "4                           0.543826                           0.523236   \n",
       "\n",
       "   Angle(t-1)  Angle(t)  \n",
       "0    0.740260  0.688312  \n",
       "1    0.688312  0.649351  \n",
       "2    0.649351  0.597403  \n",
       "3    0.597403  0.545455  \n",
       "4    0.545455  0.506494  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cols = list(range(0, num_inputs))\n",
    "sup_df_total_scaled[sup_df_total_scaled.columns[x_cols]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T03:10:28.346266Z",
     "start_time": "2021-02-09T03:10:28.328280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Angle(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.597403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.506494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.506494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Angle(t+1)\n",
       "0    0.649351\n",
       "1    0.597403\n",
       "2    0.545455\n",
       "3    0.506494\n",
       "4    0.506494"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cols = list(range(num_inputs, num_inputs+num_outputs))\n",
    "sup_df_total_scaled[sup_df_total_scaled.columns[y_cols]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split and Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T03:10:29.894096Z",
     "start_time": "2021-02-09T03:10:29.577966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66937, 54) (66937, 1) (16635, 54) (16635, 1)\n",
      "(66937, 1, 54) (66937, 1, 1) (16635, 1, 54) (16635, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "X = sup_df_total_scaled[sup_df_total_scaled.columns[x_cols]]\n",
    "y = sup_df_total_scaled[sup_df_total_scaled.columns[y_cols]]\n",
    "\n",
    "def train_test_split_chrono(X, y, num=None):\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    if num is None:\n",
    "        num = int(round(X.shape[0] * 0.75))\n",
    "    train_X = pd.DataFrame(X[:num, :])\n",
    "    test_X = pd.DataFrame(X[num:, :])\n",
    "    train_y = pd.DataFrame(y[:num, :])\n",
    "    test_y = pd.DataFrame(y[num:, :])\n",
    "    return train_X, test_X, train_y, test_y\n",
    "\n",
    "def train_test_split_datasets(df_scaled_list, scaler_list=None, num_datasets_test=1):\n",
    "    compiled_train_df = None\n",
    "    compiled_test_df = None\n",
    "    for df in df_scaled_list[:-1*num_datasets_test]:\n",
    "        if compiled_train_df is None:\n",
    "            compiled_train_df = df\n",
    "        else:\n",
    "            compiled_train_df = pd.concat([compiled_train_df, df], axis=0).reset_index(drop=True)\n",
    "    for df in df_scaled_list[-1*num_datasets_test:]:\n",
    "        if compiled_test_df is None:\n",
    "            compiled_test_df = df\n",
    "        else:\n",
    "            compiled_test_df = pd.concat([compiled_test_df, df], axis=0).reset_index(drop=True)\n",
    "    train_X = compiled_train_df[compiled_train_df.columns[x_cols]]\n",
    "    train_y = compiled_train_df[compiled_train_df.columns[y_cols]]\n",
    "    test_X = compiled_test_df[compiled_test_df.columns[x_cols]]\n",
    "    test_y = compiled_test_df[compiled_test_df.columns[y_cols]]\n",
    "    if scaler_list is not None:\n",
    "        train_scaler_list = scaler_list[:-1*num_datasets_test]\n",
    "        test_scaler_list = scaler_list[-1*num_datasets_test:]\n",
    "    else:\n",
    "        train_scaler_list = None\n",
    "        test_scaler_list = None\n",
    "    return train_X, test_X, train_y, test_y, train_scaler_list, test_scaler_list\n",
    "\n",
    "    \n",
    "\n",
    "# Split into validation and training data\n",
    "# train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=1, test_size=0.2)\n",
    "# train_X, test_X, train_y, test_y = train_test_split_chrono(X, y, 1000)\n",
    "# train_X, test_X, train_y, test_y, train_scalers, test_scaler = train_test_split_datasets(sup_df_total_scaled_list, scaler_list)\n",
    "# \n",
    "train_X, test_X, train_y, test_y, train_scalers, test_scaler = train_test_split_datasets(sup_df_total_list, num_datasets_test=5)\n",
    "\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "train_X = train_X.values.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.values.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "train_y = train_y.values.reshape(train_y.shape[0], 1, train_y.shape[1])\n",
    "test_y = test_y.values.reshape(test_y.shape[0], 1, test_y.shape[1])\n",
    "# train_y = train_y.values[:,9].reshape(train_y.shape[0], 1, 1)\n",
    "# test_y = test_y.values[:,9].reshape(test_y.shape[0], 1, 1)\n",
    "# train_X = train_X.values\n",
    "# test_X = test_X.values\n",
    "# train_y = train_y.values\n",
    "# test_y = test_y.values\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "# print(sup_df_total_scaled.columns)\n",
    "\n",
    "# ard_test_data = pd.DataFrame(test_X.reshape((test_X.shape[0], test_X.shape[2])))\n",
    "# ard_test_data.columns = X.columns\n",
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "# ard_test_data.iloc[[300]]\n",
    "\n",
    "# print(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T03:10:48.378526Z",
     "start_time": "2021-02-09T03:10:34.309905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66937 samples, validate on 16635 samples\n",
      "Epoch 1/50\n",
      "66937/66937 - 1s - loss: 66.4975 - val_loss: 22.8378\n",
      "Epoch 2/50\n",
      "66937/66937 - 0s - loss: 7.8720 - val_loss: 14.5066\n",
      "Epoch 3/50\n",
      "66937/66937 - 0s - loss: 4.8843 - val_loss: 11.7158\n",
      "Epoch 4/50\n",
      "66937/66937 - 0s - loss: 3.5795 - val_loss: 8.0581\n",
      "Epoch 5/50\n",
      "66937/66937 - 0s - loss: 2.6589 - val_loss: 5.2254\n",
      "Epoch 6/50\n",
      "66937/66937 - 0s - loss: 2.0348 - val_loss: 3.8817\n",
      "Epoch 7/50\n",
      "66937/66937 - 0s - loss: 1.6083 - val_loss: 2.8246\n",
      "Epoch 8/50\n",
      "66937/66937 - 0s - loss: 1.3393 - val_loss: 2.2900\n",
      "Epoch 9/50\n",
      "66937/66937 - 0s - loss: 1.2199 - val_loss: 1.9257\n",
      "Epoch 10/50\n",
      "66937/66937 - 0s - loss: 1.1548 - val_loss: 1.9271\n",
      "Epoch 11/50\n",
      "66937/66937 - 0s - loss: 1.1320 - val_loss: 1.6176\n",
      "Epoch 12/50\n",
      "66937/66937 - 0s - loss: 1.1283 - val_loss: 1.6214\n",
      "Epoch 13/50\n",
      "66937/66937 - 0s - loss: 1.1410 - val_loss: 1.5081\n",
      "Epoch 14/50\n",
      "66937/66937 - 0s - loss: 1.1128 - val_loss: 1.6772\n",
      "Epoch 15/50\n",
      "66937/66937 - 0s - loss: 1.1359 - val_loss: 1.6112\n",
      "Epoch 16/50\n",
      "66937/66937 - 0s - loss: 1.1287 - val_loss: 1.9549\n",
      "Epoch 17/50\n",
      "66937/66937 - 0s - loss: 1.1631 - val_loss: 1.5952\n",
      "Epoch 18/50\n",
      "66937/66937 - 0s - loss: 1.1349 - val_loss: 2.1588\n",
      "Epoch 19/50\n",
      "66937/66937 - 0s - loss: 1.1383 - val_loss: 1.5031\n",
      "Epoch 20/50\n",
      "66937/66937 - 0s - loss: 1.1122 - val_loss: 1.6576\n",
      "Epoch 21/50\n",
      "66937/66937 - 0s - loss: 1.1908 - val_loss: 1.9706\n",
      "Epoch 22/50\n",
      "66937/66937 - 0s - loss: 1.1220 - val_loss: 1.5516\n",
      "Epoch 23/50\n",
      "66937/66937 - 0s - loss: 1.1264 - val_loss: 1.4640\n",
      "Epoch 24/50\n",
      "66937/66937 - 0s - loss: 1.1202 - val_loss: 1.4981\n",
      "Epoch 25/50\n",
      "66937/66937 - 0s - loss: 1.1129 - val_loss: 1.5719\n",
      "Epoch 26/50\n",
      "66937/66937 - 0s - loss: 1.1189 - val_loss: 1.7080\n",
      "Epoch 27/50\n",
      "66937/66937 - 0s - loss: 1.1136 - val_loss: 1.5098\n",
      "Epoch 28/50\n",
      "66937/66937 - 0s - loss: 1.1487 - val_loss: 1.3272\n",
      "Epoch 29/50\n",
      "66937/66937 - 0s - loss: 1.1236 - val_loss: 1.4289\n",
      "Epoch 30/50\n",
      "66937/66937 - 0s - loss: 1.1698 - val_loss: 1.8510\n",
      "Epoch 31/50\n",
      "66937/66937 - 0s - loss: 1.0977 - val_loss: 1.5883\n",
      "Epoch 32/50\n",
      "66937/66937 - 0s - loss: 1.1382 - val_loss: 2.0641\n",
      "Epoch 33/50\n",
      "66937/66937 - 0s - loss: 1.1250 - val_loss: 1.4891\n",
      "Epoch 34/50\n",
      "66937/66937 - 0s - loss: 1.1315 - val_loss: 1.4934\n",
      "Epoch 35/50\n",
      "66937/66937 - 0s - loss: 1.1321 - val_loss: 1.6400\n",
      "Epoch 36/50\n",
      "66937/66937 - 0s - loss: 1.1447 - val_loss: 1.6102\n",
      "Epoch 37/50\n",
      "66937/66937 - 0s - loss: 1.0924 - val_loss: 1.4447\n",
      "Epoch 38/50\n",
      "66937/66937 - 0s - loss: 1.1158 - val_loss: 1.7271\n",
      "Epoch 39/50\n",
      "66937/66937 - 0s - loss: 1.1776 - val_loss: 1.5914\n",
      "Epoch 40/50\n",
      "66937/66937 - 0s - loss: 1.1264 - val_loss: 1.6724\n",
      "Epoch 41/50\n",
      "66937/66937 - 0s - loss: 1.1082 - val_loss: 1.6044\n",
      "Epoch 42/50\n",
      "66937/66937 - 0s - loss: 1.1569 - val_loss: 1.9629\n",
      "Epoch 43/50\n",
      "66937/66937 - 0s - loss: 1.1273 - val_loss: 1.4318\n",
      "Epoch 44/50\n",
      "66937/66937 - 0s - loss: 1.1604 - val_loss: 1.4029\n",
      "Epoch 45/50\n",
      "66937/66937 - 0s - loss: 1.0838 - val_loss: 1.5199\n",
      "Epoch 46/50\n",
      "66937/66937 - 0s - loss: 1.1054 - val_loss: 1.6391\n",
      "Epoch 47/50\n",
      "66937/66937 - 0s - loss: 1.1168 - val_loss: 1.3621\n",
      "Epoch 48/50\n",
      "66937/66937 - 0s - loss: 1.1353 - val_loss: 1.5480\n",
      "Epoch 49/50\n",
      "66937/66937 - 0s - loss: 1.1158 - val_loss: 1.3109\n",
      "Epoch 50/50\n",
      "66937/66937 - 0s - loss: 1.1659 - val_loss: 1.6008\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.backend import sigmoid\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(LSTM(num_inputs, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "\n",
    "model.add(Dense(num_inputs, input_shape=(1, train_X.shape[2])))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(BatchNormalization())\n",
    "# for i in range(40):\n",
    "#     model.add(Dense(30, activation='relu'))\n",
    "\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(25, activation='swish'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dense(train_y.shape[2]))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# fit network\n",
    "# for i in range(100):\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=512, validation_data=(test_X, test_y), verbose=2, shuffle=True)\n",
    "#     model.reset_states()\n",
    "    # plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T03:14:28.912338Z",
     "start_time": "2021-02-09T03:14:28.499397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16635, 54)\n",
      "(16635, 1)\n",
      "(16635, 1, 1)\n",
      "Test RMSE: 1.265\n",
      "Test MAE: 0.939\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "yhat = yhat.reshape((yhat.shape[0], yhat.shape[2]))\n",
    "# yhat = yhat.reshape((yhat.shape[0], 1))\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "print(test_X.shape)\n",
    "print(yhat.shape)\n",
    "print(test_y.shape)\n",
    "inv_yhat = concatenate((test_X, yhat), axis=1)\n",
    "# inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "# inv_yhat = test_scaler[0].inverse_transform(inv_yhat)\n",
    "# invert scaling for actual\n",
    "# test_y = test_y.reshape((len(test_y), num_outputs))\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_X, test_y), axis=1)\n",
    "# inv_y = scaler.inverse_transform(inv_y)\n",
    "# inv_y = test_scaler[0].inverse_transform(inv_y)\n",
    "\n",
    "# calculate RMSE\n",
    "for i in range(num_inputs, num_inputs+num_outputs):\n",
    "# for i in range(num_inputs, num_inputs+1):\n",
    "    rmse = sqrt(mean_squared_error(inv_y[:,i], inv_yhat[:,i]))\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "    mae = mean_absolute_error(inv_y[:,i], inv_yhat[:,i])\n",
    "    print('Test MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "#### Train Test Data Split randomly\n",
    "With Hidden Inner Layer with 25 neurons, activation = relu, loss='mae', scaled data, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 1.994  \n",
    "Test MAE: 1.410  \n",
    "Test RMSE: 2.598  \n",
    "Test MAE: 1.816  \n",
    "Test RMSE: 3.011  \n",
    "Test MAE: 2.058  \n",
    "\n",
    "With Hidden Inner Layer with 25 neurons, activation = relu, loss='mean_squared_error', scaled data, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 2.028  \n",
    "Test MAE: 1.435  \n",
    "Test RMSE: 2.571  \n",
    "Test MAE: 1.806  \n",
    "Test RMSE: 2.924  \n",
    "Test MAE: 2.082  \n",
    "\n",
    "With Hidden Inner Layer with 25 neurons, activation = swish, loss='mean_squared_error', scaled data, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles \n",
    "Test RMSE: 2.016  \n",
    "Test MAE: 1.421  \n",
    "Test RMSE: 2.624  \n",
    "Test MAE: 1.834  \n",
    "Test RMSE: 3.063  \n",
    "Test MAE: 2.151  \n",
    "\n",
    "#### Test Train Data Split Up to Last Person (Sam Sites)\n",
    "With Hidden Inner Layer with 25 neurons, activation = swish, loss='mean_squared_error', scaled data, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles \n",
    "Test RMSE: 6.888  \n",
    "Test MAE: 5.696  \n",
    "Test RMSE: 9.441  \n",
    "Test MAE: 8.059  \n",
    "Test RMSE: 11.710  \n",
    "Test MAE: 10.333  \n",
    "\n",
    "With Hidden Inner Layer with 25 neurons, activation = relu, loss='mean_squared_error', scaled data, batch=72, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 10.138  \n",
    "Test MAE: 8.945  \n",
    "Test RMSE: 11.869  \n",
    "Test MAE: 10.049  \n",
    "Test RMSE: 13.293  \n",
    "Test MAE: 11.266  \n",
    "\n",
    "With Hidden Inner Layer with 25 neurons, activation = relu, loss='mean_squared_error', scaled data, batch=144, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 6.039\n",
    "Test MAE: 5.116\n",
    "Test RMSE: 7.483\n",
    "Test MAE: 6.294\n",
    "Test RMSE: 10.444\n",
    "Test MAE: 8.451\n",
    "\n",
    "With Hidden Inner Layer with 25 neurons, activation = swish, loss='mean_squared_error', scaled data, batch=144, Shuffle=False, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 8.199  \n",
    "Test MAE: 7.136  \n",
    "Test RMSE: 10.291  \n",
    "Test MAE: 8.630  \n",
    "Test RMSE: 12.340  \n",
    "Test MAE: 10.175  \n",
    "\n",
    "With Hidden Inner Layer with 25 neurons, activation = relu, loss='mean_squared_error', scaled data, batch=144, shuffle=True, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 3.181\n",
    "Test MAE: 2.592\n",
    "Test RMSE: 5.544\n",
    "Test MAE: 4.516\n",
    "Test RMSE: 6.759\n",
    "Test MAE: 5.522\n",
    "\n",
    "With Hidden Inner Layer with 25 neurons, activation = swish, loss='mean_squared_error', scaled data, batch=144, shuffle=True, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 3.908  \n",
    "Test MAE: 3.055  \n",
    "Test RMSE: 6.584  \n",
    "Test MAE: 5.296  \n",
    "Test RMSE: 9.247  \n",
    "Test MAE: 7.864  \n",
    "\n",
    "With Hidden Inner Layer with 25 neurons, activation = relu, loss='mae', scaled data, batch=144, shuffle=True, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 3.807  \n",
    "Test MAE: 3.059  \n",
    "Test RMSE: 6.058  \n",
    "Test MAE: 4.812  \n",
    "Test RMSE: 8.032  \n",
    "Test MAE: 6.357  \n",
    "\n",
    "With Hidden Inner Layer with 25 neurons, activation = relu, loss='mean_squared_error', scaled data, batch=144, shuffle=True, added Normalization and Dropout=0.3, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 3.894\n",
    "Test MAE: 3.194\n",
    "Test RMSE: 5.357\n",
    "Test MAE: 4.506\n",
    "Test RMSE: 7.164\n",
    "Test MAE: 5.903\n",
    "\n",
    "With Hidden Inner Layer with 25 neurons, activation = swish, loss='mean_squared_error', scaled data, batch=144, shuffle=True, added Normalization and Dropout=0.3, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 4.540\n",
    "Test MAE: 3.910\n",
    "Test RMSE: 6.023\n",
    "Test MAE: 5.128\n",
    "Test RMSE: 8.465\n",
    "Test MAE: 7.191\n",
    "\n",
    "With 2 Hidden Inner Layers with 25 neurons, activation = relu, loss='mean_squared_error', scaled data, batch=144, shuffle=True, added Normalization and Dropout=0.3, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 6.378\n",
    "Test MAE: 5.629\n",
    "Test RMSE: 7.147\n",
    "Test MAE: 6.161\n",
    "Test RMSE: 8.623\n",
    "Test MAE: 7.372\n",
    "\n",
    "loss='mean_squared_error', scaled data, batch=144, shuffle=True, added Normalization and Dropout=0.3, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 4.412\n",
    "Test MAE: 3.776\n",
    "Test RMSE: 6.409\n",
    "Test MAE: 5.480\n",
    "Test RMSE: 8.680\n",
    "Test MAE: 7.300\n",
    "\n",
    "loss='mean_squared_error', scaled data, batch=144, shuffle=True, added Dropout=0.3, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 3.365\n",
    "Test MAE: 2.675\n",
    "Test RMSE: 5.452\n",
    "Test MAE: 4.232\n",
    "Test RMSE: 8.044\n",
    "Test MAE: 6.605\n",
    "\n",
    "With Hidden Inner Layer with 25 neurons, activation = swish, loss='mean_squared_error', scaled data, batch=144, shuffle=True, added Dropout=0.3 ONLY BEFORE hidden layter, uses current knee angle and three previous knee angles for inputs -- predicts next three knee angles  \n",
    "Test RMSE: 3.285\n",
    "Test MAE: 2.584\n",
    "Test RMSE: 4.791\n",
    "Test MAE: 4.089\n",
    "Test RMSE: 6.863\n",
    "Test MAE: 5.877"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Model to C++ Code\n",
    "## Converting LSTM RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T23:57:03.250385Z",
     "start_time": "2021-01-21T23:56:56.600006Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import sklearn.model_selection\n",
    "import logging\n",
    "import numpy as np\n",
    "import hexdump\n",
    "\n",
    "keras_model_dir = os.getcwd() + \"\\\\keras_models\\\\\"\n",
    "filename_wo_dir = 'lstm_knee_angle'\n",
    "filename = keras_model_dir + filename_wo_dir\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.experimental_new_converter = True\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "\n",
    "def rep_data_gen():\n",
    "    for val in test_X:\n",
    "        yield [np.array(val, dtype=np.float32, ndmin=2)]\n",
    "        \n",
    "converter.representative_dataset = rep_data_gen\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open(filename + '.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T01:22:22.139085Z",
     "start_time": "2021-01-15T01:22:22.116125Z"
    }
   },
   "outputs": [],
   "source": [
    "# for testing if operations are implemented by Tensorflow Lite\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T01:22:22.216846Z",
     "start_time": "2021-01-15T01:22:22.143040Z"
    }
   },
   "outputs": [],
   "source": [
    "keras_model_dir = os.getcwd() + \"\\\\keras_models\\\\\"\n",
    "filename_wo_dir = 'lstm_knee_angle'\n",
    "filename = keras_model_dir + filename_wo_dir\n",
    "\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "    c_str = ''\n",
    "    \n",
    "    # Create Header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n'\n",
    "    \n",
    "    # Add array length at top of file\n",
    "    c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "    \n",
    "    # Declare C variable\n",
    "    c_str += 'unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data):\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "        \n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "        \n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "    \n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "    \n",
    "    return c_str\n",
    "\n",
    "with open(filename + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model, filename_wo_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T00:22:49.322884Z",
     "start_time": "2021-01-22T00:22:48.703604Z"
    }
   },
   "outputs": [],
   "source": [
    "from tinymlgen import port\n",
    "\n",
    "c_code = port(model, optimize=False, pretty_print=True)\n",
    "\n",
    "print(len(c_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T00:00:56.411178Z",
     "start_time": "2021-01-22T00:00:56.385695Z"
    }
   },
   "outputs": [],
   "source": [
    "keras_model_dir = os.getcwd() + \"\\\\keras_models\\\\\"\n",
    "filename_wo_dir = 'lstm_knee_angle'\n",
    "filename = keras_model_dir + filename_wo_dir\n",
    "\n",
    "c_file = open(filename + '.h', 'w+')\n",
    "\n",
    "n = c_file.write(c_code)\n",
    "c_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T16:19:48.489938Z",
     "start_time": "2021-01-20T16:19:33.884666Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tinymlgen import port\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    np.random.seed(1337)\n",
    "    x_values, y_values = load_digits(return_X_y=True)\n",
    "    x_values /= x_values.max()\n",
    "    # reshape to (8 x 8 x 1)\n",
    "    x_values = x_values.reshape((len(x_values), 8, 8, 1))\n",
    "\n",
    "    # split into train, validation, test\n",
    "    TRAIN_SPLIT = int(0.6 * len(x_values))\n",
    "    TEST_SPLIT = int(0.2 * len(x_values) + TRAIN_SPLIT)\n",
    "    x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "    y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "    return x_train, x_test, x_validate, y_train, y_test, y_validate\n",
    "\n",
    "def get_model():\n",
    "    x_train, x_test, x_validate, y_train, y_test, y_validate = get_data()\n",
    "\n",
    "    # create a CNN\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(8, (3, 3), activation='relu', input_shape=(8, 8, 1)))\n",
    "    # model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    # model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    # model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(len(np.unique(y_train))))\n",
    "\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=16,\n",
    "              validation_data=(x_validate, y_validate))\n",
    "    return model, x_test, y_test\n",
    "\n",
    "\n",
    "def test_model(model, x_test, y_test):\n",
    "    x_test = (x_test / x_test.max()).reshape((len(x_test), 8, 8, 1))\n",
    "    y_pred = model.predict(x_test).argmax(axis=1)\n",
    "    print('ACCURACY', (y_pred == y_test).sum() / len(y_test))\n",
    "    exit()\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "model, x_test, y_test = get_model()\n",
    "test_model(model, x_test, y_test)\n",
    "c_code = port(model, optimize=False, variable_name='digits_model', pretty_print=True)\n",
    "print(c_code)\n",
    "# keras_model_dir = os.getcwd() + \"\\\\keras_models\\\\\"\n",
    "# filename_wo_dir = 'lstm_knee_angle'\n",
    "# filename = keras_model_dir + filename_wo_dir\n",
    "\n",
    "# c_file = open(filename + '.h', 'w+')\n",
    "\n",
    "# n = c_file.write(c_code)\n",
    "# c_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T08:21:37.412976Z",
     "start_time": "2021-01-20T08:21:33.812057Z"
    }
   },
   "outputs": [],
   "source": [
    "import tinymlgen as tmg\n",
    "\n",
    "print(tmg.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "495px",
    "width": "307.5px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
